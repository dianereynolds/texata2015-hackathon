{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texata finals 2015\n",
    "Álvaro Barbero Jiménez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will compute the semantic embedding models required for some of the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the data I previously loaded into Elasticsearch, by making use of the convenient PostsCorpus class I created. This way I don't need to keep all the data in memory, instead I can efficiently iterate through the text stored in ElasticSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CISCO data embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will create a semantic embedding by using all the data provided by CISCO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from texata import text\n",
    "corpus = text.PostsCorpus([\"support-forums\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute a word2vec embedding using all the texts in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from texata import semantic\n",
    "model = semantic.computewordembedding(corpus)\n",
    "model.save('models/word2vec-cisco.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stackexchange embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also compute and embedding using data from some relevant communities of Stackexchange. I hope that with this I will capture a significant vocabulary of tech-words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from texata import text\n",
    "corpus = text.PostsCorpus([\n",
    "        \"dsp.stackexchange.com\", \n",
    "        \"networkengineering.stackexchange.com\",\n",
    "        \"reverseengineering.stackexchange.com\",\n",
    "        \"robotics.stackexchange.com\",\n",
    "        \"security.stackexchange.com\",\n",
    "        \"serverfault.com\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from texata import semantic\n",
    "model = semantic.computewordembedding(corpus)\n",
    "model.save('models/word2vec-stackexchange.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
